---
title: Anthropic CEO 万字访谈：亲述丧父之痛、炮轰黄仁勋、揭秘指数定律与 AI 未来
description: Anthropic CEO 万字访谈
date: 2025-08-09T03:01:00.000Z
---
> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [blog.csdn.net](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/149843991?spm=1000.2115.3001.5926)

![](https://i-blog.csdnimg.cn/img_convert/476e35df99bb674f52940984df5d2a37.png)

责编 | 王启隆

出品 | CSDN（ID：CSDNnews）

投稿或寻求报道 | zhanghy@csdn[.net](https://so.csdn.net/so/search?q=.net&spm=1001.2101.3001.7020)

在[人工智能](https://so.csdn.net/so/search?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&spm=1001.2101.3001.7020)这场关乎未来的豪赌中，Anthropic CEO Dario Amodei 是一个无法被简单归类的角色。

他既是推动技术指数级发展的核心人物，也是国会山最忧心忡忡的 “吹哨人”。

他在 [OpenAI](https://so.csdn.net/so/search?q=OpenAI&spm=1001.2101.3001.7020) 风头无两的那一年打造了足以与 GPT-4o 媲美的 Claude 3 Opus，并在今年推出了编程能力数一数二的 Claude 4 模型。而在另一边，Amodei 经常疾呼这项技术的潜在风险，甚至不惜惹恼像英伟达 CEO 黄仁勋这样的行业巨头。

![](https://i-blog.csdnimg.cn/img_convert/d2ec54823af9ffebaf0f9cc0fb645593.png)

这种看似矛盾的立场，让他饱受非议。有人称他为 “末日论者”，认为他危言耸听，只是为了巩固自家公司的领先地位，甚至想借安全之名，“控制整个行业”。面对这样的指控，Amodei 在接下来和 Big Technology 播客的 Alex Kantrowitz 的对话中给出了迄今最激烈、最坦诚的回应：“那是我听过最无耻、最离谱的谎言。”

![](https://i-blog.csdnimg.cn/img_convert/cc6769cfbf99beed3487936e7c059960.png)

Amodei 罕见地谈及了个人经历对他事业选择的深刻影响：“我父亲因那些本可能晚几年就出现的疗法而离世。所以当有人说我想放慢脚步时，我感到非常、非常愤怒。” 这句话，或许才是理解他一切行为的关键。他比任何人都清楚技术加速的价值，也正因如此，他比任何人都恐惧失控的代价。

Amodei 坚信，我们正处在一个巨大的 “指数定律” 时代，AI 的能力正以超乎想象的速度攀升。这种紧迫感，源于他对未来的清晰预判，也让他对行业的浮躁与短视感到极度不安。他认为，真正的竞争不在于一时的模型跑分，而在于能否建立一种负责任、有远见的文化，吸引最顶尖、最有使命感的人才。

以下是这场对话的内容，由 CSDN 进行了精编整理。

· · ·

![](https://i-blog.csdnimg.cn/img_convert/2f5e47c4c70f3810eecf0a443e460b46.png)

#### **我说的越多，只是因为我们离悬崖越近**

主持人：让我们回顾一下你过去几个月的经历。

*   你曾说 AI 可能会让一半的入门级白领工作消失；
    
*   当你得知 OpenAI 打算收购 Windsurf 时，你切断了 Windsurf 对 Anthropic 顶级模型的访问权限；
    
*   你要求政府实施出口管制，结果惹恼了英伟达 CEO 黄仁勋。
    

你这是怎么了？

Dario Amodei：嗯，你知道，我认为 Anthropic，包括我个人，一直以来都专注于践行和言说我们所坚信的理念。

我认为，随着我们离那些更强大的 AI 系统越来越近，我希望更用力、更公开地去言说这些理念，把观点讲得更清楚。多年来我一直在说，我们有这些规模法则（Scaling Laws）——我们可以详细聊聊——AI 系统的能力正在变得越来越强。它们正从几年前几乎语无伦次的水平，发展到现在。几年前，它们大概是聪明的初中生水平；现在，我们正接近聪明的大学生、博士生水平，并且开始在整个经济体中得到应用。

所以，我认为所有与 AI 相关的问题，从国家安全到经济影响，都开始变得非常现实，离我们非常近了。因此，随着这些问题越来越近，即便 Anthropic 在某种形式上已经谈论这些事情有一段时间了，但我认为这些事情的紧迫性已经大大增加了。

而且，你知道，我希望确保我们说出我们所相信的，并且我们就未来可能发生的风险向世界发出警告。即便没人能确切地说会发生什么。我们只是在说我们认为_可能_会发生什么，我们认为_很可能_会发生什么。我们尽力用证据支持我们的观点，尽管这往往是基于对未来的推断，没人能百分之百确定。

但我认为，我们视自己有责任去就即将发生的事情向世界发出警告。这并不是说，我认为 AI 没有海量的积极应用。我一直在谈论这一点，我写过那篇名为《充满慈爱的机器》（Machines of Loving Grace）的文章。

事实上，我感觉我和 Anthropic 往往能比那些自称为 “乐观主义者” 或“加速主义者”的人，更好地阐述 AI 的益处。所以我认为我们可能比任何人都更理解这项技术的好处。但正因如此，正因为我们有机会在一切都做对的情况下，创造一个如此美好的世界，我才感到有责任就其风险发出警告。

主持人：所以，你所有的这些行为，都源于你的时间线判断。基本上，你似乎比大多数人有一个更短的时间线，所以你感到一种紧迫感，要去大声疾呼，因为你认为这一切都迫在眉睫。

Dario Amodei：是的。我并不百分之百确定。我认为预测未来非常困难，尤其是在社会影响层面。比如你说，人们何时会部署 AI？公司何时会投入 X 亿美元在 AI 上？或者 AI 何时会被用于那些医疗突破？这很难说。底层的技术发展更具可预测性，但仍然存在不确定性，没人真的知道。

但我认为，在底层技术层面，我开始变得更有信心。当然，不确定性并非完全没有。我认为我们所处的指数增长曲线，完全有可能停滞。我觉得大概有 20% 或 25% 的可能性，在未来两年内的某个时候，模型就停止进步了，原因可能是我们不理解的，也可能是我们能理解的，比如数据或算力的可用性。到那时，我说的每句话都会显得很傻，每个人都会因为我发出的所有警告而嘲笑我。你知道，考虑到我所看到的可能性分布，我完全接受那种结果。

主持人：我得说明一下，这次对话是我正在为你撰写的一篇人物特写的一部分。我已经和超过二十位与你共事过、了解你、与你竞争过的人聊过。但在我与所有人交流的过程中，有一个主题贯穿始终，那就是在所有主流实验室的负责人中，你的时间线判断几乎是最短的。你刚才也提到了这一点。那么，为什么你的时间线这么短？我们又为什么要相信你的判断？

Dario Amodei：这真的取决于你说的 “时间线” 具体指什么。

比如说，有一些术语在 AI 圈子里很流行，像 AGI（通用人工智能）和超级智能。你会听到一些公司领导说，我们已经实现了 AGI，正在向超级智能迈进。

说实话，我觉得这些词完全没有意义。我不知道什么是 AGI，也不知道什么是超级智能。 它听起来像个营销术语，像是为了激活人们的多巴胺而设计的。所以你会发现，在公开场合，我从不使用这些词，而且我还会很小心地去批评这些词的使用。

![](https://i-blog.csdnimg.cn/img_convert/aaa772ae72785e1d23e19e8bf6c36917.png)

#### **指数定律，才是唯一真实的东西**

Dario Amodei：但我认为，尽管如此，我确实是对 AI 能力将极速提升这件事最乐观的人之一。我认为唯一真实的东西，就是那条指数曲线。这个概念是：每隔几个月，我们就会得到一个比上一个更强的 AI 模型。而我们之所以能做到这一点，是因为我们投入了更多的算力、更多的数据，以及更多新型的训练方法。

最初，这是通过所谓的 “预训练” 完成的，就是你把互联网上的海量数据喂给模型。现在，我们有了第二阶段，也就是强化学习，或者叫测试时计算、推理等等，你怎么称呼它都行。我认为这是一个涉及强化学习的第二阶段。现在，这两个阶段都在同步扩展，我们从我们自己的模型和其他公司的模型中都看到了这一点。

我没有看到任何东西能阻碍这种规模化的进一步发展。

当然，有一些问题，比如我们如何拓宽强化学习阶段的任务范围。我们已经看到在数学和代码方面取得了更多进展，模型的水平正接近高级专业人士。但在更主观的任务上，进展就少一些。但我认为这只是一个暂时的障碍。

所以，当我审视这一切时，我看到了这条指数曲线，然后我说：“看，人类并不擅长理解指数增长。” 对吧？就像，如果某个东西每六个月翻一番，那么在它真正爆发的两年前，它看起来只完成了整个过程的十六分之一。

而我们现在就坐在这里，在 2025 年年中，模型的各项能力正开始在经济领域爆炸式增长。如果你看模型的性能，它们已经开始在所有基准测试中达到饱和。如果你看营收，Anthropic 的营收每年都增长 10 倍。每年，我们都很保守，说：“不可能再增长 10 倍了。” 每年我都非常保守地说：“唉，我觉得业务增长要放缓了。” 但事实是，我们从 2023 年的 0 增长到了 1 亿美元，2024 年从 1 亿增长到了 10 亿。而今年，上半年我们就从 10 亿增长到了…… 我想到今天为止，已经远超 40 亿，可能是 45 亿。

所以你想想，假设这条指数曲线再持续两年——我不是说它一定会——但如果它持续下去，你的营收会轻松进入千亿级别。我不是说这一定会发生。我想说的是，当你身处一条指数曲线上时，你真的很容易被迷惑。距离指数曲线变得彻底疯狂还有两年的时候，它看起来却像是刚刚起步。

这就是最根本的动态。我们在 90 年代的互联网发展中也看到了这一点，对吧？当时网络速度和计算机底层速度都在快速提升，在短短几年内，建立一个全球数字通信网络就成为了可能，而这在几年前是无法想象的。而当时，除了少数几个人，几乎没人真正预见到这其中的含义以及它发生的速度。

这就是我的出发点，我的思考方式。当然，我不知道未来会怎样。比如，如果一堆卫星坠毁，互联网的发展可能就会变慢。如果发生经济危机，也可能变慢。所以我们无法确定确切的时间线，但我认为，人们正在被指数曲线所迷惑，没有意识到事情可能——我认为是很可能——会发展得有多快，尽管我也不确定。

主持人：但 AI 行业的很多人都在谈论规模化带来的 “收益递减”。这似乎与你刚才描绘的愿景不太相符。他们错了吗？

Dario Amodei：是的。从我们所看到的情况来看——我只能就 Anthropic 的模型而言——我认为他们错了。

我们以代码为例。这是 Anthropic 模型进步很快的一个领域，市场采用率也很高。我们不仅仅是一家代码公司，我们计划扩展到很多领域。但如果你单看代码，我们发布了 3.5 Sonnet，然后是一个我们称之为 3.5 Sonnet V2 的模型——咱们就叫它 3.6 Sonnet 吧——然后是 3.7 Sonnet，再到 4.0 Sonnet 和 4.0 Opus。

这四五个模型系列，每一个在代码能力上都比上一个有了显著的提升。如果你看基准测试，比如 SWE-bench，它的得分从大概 18 个月前的 3% 左右，增长到了现在根据评测方式不同，在 72% 到 80% 之间。而实际的使用率也呈指数级增长。我们正越来越多地走向可以自主使用这些模型的方向。实际上，在 Anthropic 内部，大部分代码都是由 Claude 模型编写或在其参与下完成的。

所以，我们看到的进展非常快，指数曲线仍在继续，我们没有看到任何收益递减。

![](https://i-blog.csdnimg.cn/img_convert/0d48badc8993fd4fff0a68311b61bb38.png)

#### **AI 时代，技术护城河的消亡与重生**

主持人：但大语言模型似乎确实存在一些固有的缺陷，比如 “持续学习”（Continual Learning）的能力。我们几周前请了 Dwarkesh，他认为缺乏持续学习能力是个巨大的问题。“大模型的基线能力可能比普通人强，但你就被困在了它出厂时的水平。” 模型被创造出来后，它就不再学习了。这似乎是一个 glaring liability（明显的缺陷）。你怎么看？

Dario Amodei：首先，我想说，即便我们永远解决不了持续学习和记忆的问题，大模型影响经济规模的潜力也依然巨大。如果我回想我以前的领域，生物学和医学，比如说，我有一个非常聪明的诺奖得主，然后我说：“好吧，你虽然发现了所有这些东西，拥有这个无比聪明的头脑，但你不能再读新的教科书，也不能吸收任何新信息了。”

这当然会很困难，但如果你有一千万个这样的 “诺奖得主”，他们仍然会取得大量的生物学突破，对吧？他们会受到限制，有些事情人类能做他们做不了，有些他们能做人类做不了。但即便我们把这个当作上限，天哪，那也已经非常了不起，足以改变世界了。

但话说回来，上下文窗口正在变得越来越长，而模型实际上在上下文窗口内确实在学习。对吧？所以当我和模型在对话中交谈时，我进行了一场对话，它吸收了信息。虽然底层的模型权重可能没有改变，但就像我和你现在交谈一样，我倾听你说的话，然后我思考，然后我回应。模型也能做到这一点。

从机器学习的角度看，我们没有理由不能把上下文长度做到一亿个词，这大概是一个人一生中听到的词汇量。今天就可以。真正限制我们的是推理成本。所以，即便只是这样，也填补了许多空白。不是所有空白，但填补了很多。

然后，还有很多关于学习和记忆的技术，确实能让我们更新模型权重。我们多年前讨论过 “内循环” 和“外循环”的概念。内循环就像我在一个情境（episode）中学到一些东西，然后在外循环中，智能体在多个情境之间学习。也许这种内外循环结构就是实现持续学习的一种方式。

我们在 AI 领域学到的一件事是，每当你觉得有一个根本性的障碍时，比如两年前我们认为推理能力是一个根本障碍，结果发现，用强化学习（RL）去训练，让模型写下思考过程，就能解决。所以，在不透露太多细节的情况下，我认为，并且我们已经有一些初步证据表明，持续学习是另一个看似困难，但实际上并非如此的问题。它最终会屈服于规模化，以及一种稍微不同的思考方式。

主持人：你对规模化的痴迷，是否可能让你忽视了一些新技术？[比如 Demis Hassabis （ DeepMind CEO ）就说，要达到 AGI ，我们可能需要一些新技术。](https://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&mid=2247587906&idx=1&sn=6d76ccfd64adcfaf0373be4853ae606d&scene=21#wechat_redirect "比如 Demis Hassabis （ DeepMind CEO ）就说，要达到 AGI ，我们可能需要一些新技术。")如果你的注意力全在规模化上，会不会错过这些？

Dario Amodei： 我们每天都在开发新技术。

Claude 在代码方面非常出色，我们不怎么对外谈论为什么 Claude 在代码方面这么好。

主持人：它为什么这么好？

Dario Amodei：（笑）就像我说的，我们不怎么对外谈论。

我们发布的每一个新版本的 Claude，都在架构、我们输入的数据，以及我们用来训练它的方法上有所改进。所以我们一直在开发新技术，它们是我们构建每一个模型的一部分。这就是为什么我一直说，我们试图尽可能地优化 “人才密度”（talent density）。你需要那种人才密度，才能发明出新技术。

![](https://i-blog.csdnimg.cn/img_convert/89042be91d030dc3e3bf04ad9970eaa3.png)

#### **公司文化，决定了你能否拥有最顶尖的人才**

主持人：有一种观点认为，Anthropic 可能拥有正确的理念，但却缺乏与之匹配的资源。你看 xAI 和 Meta 正在发生的事情，马斯克建了他的超级计算集群，扎克伯格正在建一个 5GW 的数据中心。他们投入了如此巨大的资源来扩大规模。Anthropic 真的能跟上吗？

Dario Amodei：我们已经融资了…… 我想截至目前，接近 200 亿美元。这不算少。而且，如果你看看我们正在建设的数据中心的规模，比如和亚马逊合作的那些，我不认为我们的数据中心规模化速度比这个领域的任何其他公司慢多少。

很多时候，这些事情受限于能源、资本化。当你听到那些巨额数字的公告时，有时它们还没有完全落实资金，而且是分几年投入的。我们看过其他公司正在建设的数据中心的规模，我们非常有信心，我们…… 我们的规模会和他们在一个大致的范围内。

主持人：那你怎么看扎克伯格在人才密度方面所做的事情？把那种人才密度和巨大的数据中心结合起来，他似乎具备了很强的竞争力。

Dario Amodei：是的，这其实非常有趣。因为我们注意到的一件事是，相对于其他公司，很少有 Anthropic 的人被他们挖走。这并不是因为他们没努力。我跟很多在 Anthropic 收到他们 offer 的人聊过，他们直接就拒绝了。他们甚至都不愿意和扎克伯格谈，他们说：“不，我要留在 Anthropic。”

我们对此的普遍回应是，我在全公司的 Slack 里发了一条消息，我说：“看，我们不愿意为了单独回应这些 offer，而牺牲我们的薪酬原则和公平原则。” 在 Anthropic，我们的工作方式是，有一系列的级别，当候选人进来时，他们会被定级，我们不就这个级别进行谈判。因为我们认为那不公平。我们想要一个系统化的方式。

如果，马克 · 扎克伯格对着一个靶子扔飞镖，正好射中了你的名字，那并不意味着你的薪水就应该比你旁边那个和你一样有才华、一样技能娴熟的同事高 10 倍。

在我看来，在这种情况下，唯一能真正伤害到你的，就是你因为恐慌而允许这种行为破坏你公司的文化，因为你试图不公平地对待员工来保住他们。

而我认为，这实际上是公司的一个凝聚人心的时刻。我们没有屈服，我们拒绝牺牲我们的原则，因为我们有信心，留在 Anthropic 的人是因为他们真正相信公司的使命。

我相信，AI 领域的公司文化，最终决定了你能否拥有最顶尖的人才。 我认为他们正在试图购买一些无法用钱买到的东西，那就是对使命的认同。这里面存在选择效应。他们得到的，是那些最热情、最有使命感、最兴奋的人吗？

主持人：但他们有海量的 GPU。你不低估这一点吗？

Dario Amodei：我们拭目以待。我个人对他们正在做的事情相当看空（bearish）。

![](https://i-blog.csdnimg.cn/img_convert/e3b8d5bfe56d48d1513caa46a927c0f6.png)

#### **押注企业级市场**

主持人：让我们来谈谈你的业务。很多人都在好奇，生成式 AI 的生意到底是不是一门好生意。你已经融资了近 200 亿美元，谷歌投了 30 亿，亚马逊 80 亿，还有新一轮由 Lightspeed 领投的 35 亿。你的融资故事是什么？因为你不像那些大科技公司有现成的业务可以嫁接。你是直接拿着规模法则去跟投资人说 “给我点钱” 吗？

Dario Amodei：我对这个问题的看法一直是，人才才是最重要的。

你想想，三年前，我们才融资了几亿美元。OpenAI 已经从微软拿了 130 亿美元，更不用说那些万亿市值的科技巨头，他们账上躺着千亿、两千亿美元。我们当时的融资故事是：我们知道如何比别人更好地制造这些模型。

可能有一条规模法则的曲线，但如果我们在一个可以用 1 亿美元做到别人 10 亿美元才能做到的事情的位置上，可以用 100 亿美元做到别人 1000 亿美元才能做到的事情，那么投资 Anthropic 的资本效率就高 10 倍。你是愿意投资一个可以用便宜 10 倍的成本做任何事的公司，还是愿意投资一个一开始钱就更多的公司？

如果你能用便宜 10 倍的成本做事，那么资金短缺只是一个暂时的缺陷，是可以弥补的。而如果你拥有这种内在的能力，能用同样的价格构建更好的产品，或者用更低的价格构建同样好的产品，投资人不是傻子，他们理解资本效率的概念。

所以，我们从三年前资本相差近千倍的局面，走到了今天，你问我用 200 亿能否与 1000 亿竞争。我的回答是：能，因为我们的人才密度。

主持人：CNBC 报道说，Anthropic 60%-75% 的销售额来自 API。这是否意味着你在下最纯粹的技术赌注？

Dario Amodei：我不会这么说。我会说，我们押注的是模型的商业应用场景，而不是单纯的 API。只是恰好，最早的商业应用场景是通过 API 实现的。

如你所说，OpenAI 非常专注于消费者端。谷歌非常专注于将其整合到现有产品中。而我们的观点是，企业级 AI 的应用潜力，即便不比消费者端更大，也至少是同等级别的。

而且我认为，作为一个专注于商业应用场景的公司，这给了我们更好的激励去把模型做得更好。

我来举个思想实验。假设我有一个模型，它在生物化学方面的水平相当于一个本科生。然后我改进了它，让它的水平相当于一个博士生。如果我把这个模型给一个普通消费者，我说：“好消息！我把模型的生物化学能力从本科生提升到了研究生水平！” 大概 1% 的消费者会在意这个，对吧？99% 的人会说：“我反正也看不懂。”

但现在，假设我去找辉瑞，我说我把模型从本科生水平提升到了研究生水平。这会是天大的事，对吧？他们可能愿意为此多付 10 倍的钱，因为它能创造 10 倍的价值。

所以，我们的总目标，是让模型解决世界上的问题，让它们越来越聪明，同时也能带来很多积极的应用。我之前在《慈爱机器》（Machines of Loving Grace）里写的那些，解决生物医药的问题、地缘政治的问题、经济发展的问题，当然也包括金融、法律、生产力、保险这些更实际的领域。

我认为，押注商业应用，能提供更好的激励来推动模型的发展。从很多方面来说，这可能是比消费者端更有利可图的生意。

主持人：你最初是怎么决定专注于代码这个应用场景的？

Dario Amodei：一开始，像大多数事情一样，我们是想让模型在很多方面都变得更好。然后，代码这个领域就脱颖而出了。

我跟成千上万的工程师合作过。大概一年半前，我合作过的最优秀的工程师之一说，以前所有的代码模型对他来说都没用，但我们的新模型终于能帮他做一些他自己做不到的事情了。当我们发布它之后，市场采用率迅速提升。

所以当我们看到它如此受欢迎之后，我们就加倍投入了。我的看法是，代码特别有趣，因为 A) 市场采用速度快，B) 让我们在代码方面做得更好，又能反过来帮助我们开发下一个模型。所以它有很多优势。

![](https://i-blog.csdnimg.cn/img_convert/ef4fc20e4fea65ab543d8c97e87fbf93.png)

#### **个人经历、风险与 “末日论者” 的标签**

主持人：你曾说你的父亲因为晚了几年才出现的疗法而去世。我知道这很私人，但你能分享一下这对你的影响吗？

Dario Amodei：当然。我的父亲确实病了很长时间，最终在 2006 年去世了。那件事确实是促使我——我之前没提过，在我进入 AI 领域之前，我先进入了生物学领域。

我到普林斯顿的时候，是想成为一名理论物理学家，我最早的几个月也确实在做宇宙学的研究。那段时间，我父亲去世了。那件事对我影响很大，也是说服我转向生物学的原因之一，我想去解决人类的疾病和生物问题。

所以我开始和我们系里那些做生物物理和计算神经科学的人交流，这导致了我转向生物学和计算神经科学。后来，我最终进入 AI 领域，其实也是这种动机的延续。因为我在生物学领域待了很多年之后，我意识到，生物学问题的复杂性，感觉已经超出了人类的尺度。你需要成百上千的研究人员，而他们往往难以协作。

而 AI，我当时刚开始看到它的突破，感觉是唯一能弥合这个差距的技术，能把我们带到人类尺度之外，去真正理解和解决生物学问题。所以，是的，这里面有一条贯穿始终的线。

主持人：我听说，他得的病在他生病时基本是无法治愈的，但在他去世后不久，就有了重大的治疗进展，变得可以管理了。

Dario Amodei：是的，是的，那是真的。实际上，在他去世后大概三四年，他得的那种病的治愈率从 50% 提高到了大概 95%。

主持人：眼睁睁看着父亲被一种本可以被治愈的疾病夺走生命，那种感觉一定充满了不公。

Dario Amodei：当然，当然。但这也告诉你，解决这些相关问题的紧迫性有多大。对吧？肯定有人在研究那种病的疗法，他们最终成功了，拯救了很多生命。但如果他们能早几年找到疗法，就能拯救更多人的生命。

我认为这就是这里的矛盾之处，对吧？AI 有所有这些好处，我希望每个人都能尽快享受到。我可能比任何人都更理解这些好处有多么紧迫，因为我亲身经历过。

所以，我真的理解其中的利害关系。当我在公开场合谈论 AI 的风险，说我担心这些风险时，我非常、非常愤怒，当有人称我为 “末日论者” 的时候。我真的非常愤怒。 当有人说：“这家伙是个末日论者，他想让事情慢下来。”

你听到我刚才说的了吗？我的父亲因为那些本可能晚几年就出现的疗法而离世。我理解这项技术的价值。

当我坐下来写《慈爱机器》时，我写下了所有能让数十亿人生活变得更好的方式。而那些在推特上为 “加速” 欢呼的人，我不认为他们对这项技术的好处有一种人文主义的理解。他们的大脑里充满了肾上腺素，他们想为某件事欢呼，想加速。我不觉得他们在乎。

所以当这些人叫我 “末日论者” 时，我认为他们完全、完全丧失了这么做的道德信誉。这真的让我对他们失去尊重。

主持人：你对这项技术的掌控能力，似乎是你所有行动的前提。但你对影响力的渴望，是否可能促使你在加速这项技术的同时，低估了 “控制” 本身可能并不可行的风险？

Dario Amodei：我认为我比这个行业里的任何人都更多地警告过这项技术的危险。我们刚刚花了十几二十分钟，谈论了一大堆经营着万亿美元公司的人批评我谈论技术危险的事情。

现在有美国政府的官员，有经营着四万亿美元公司的人，批评我谈论技术的危险，给我安上各种奇怪的动机，这些动机和我说的、做的任何事情都毫无关系。

但我还是会继续这么做。

实际上，我认为，随着营收和经济业务的指数级增长——如果我是对的，几年后这将是世界上最大的产业——我们面临着一个可怕的局面：有数千亿、数万亿，甚至我估计有 20 万亿美元的资本，都站在 “尽可能快地加速 AI” 这一边。而我们这家公司，虽然绝对价值很高，但相对而言很小，600 亿美元。

我一直在发声，即便这会让政府里的一些人、一些巨头不高兴。我每次这么做，都会受到很多同行的攻击。但我还是要继续做。

如果我认为，我们完全没有办法控制这项技术——而我完全看不到任何证据支持这个论点，我们发布的每一个模型，我们对它的控制能力都在变强——如果我认为没有办法，那我就会站出来说：“每个人都应该停止开发这些东西，甚至是中国也应该停下来。”

我警告风险，就是为了我们不必慢下来。为了我们能投资于安全技术，继续这个领域的进步。这需要一个巨大的经济努力。就算一家公司愿意放慢脚步，也阻止不了其他公司，也阻止不了我们的地缘政治对手。

所以，我们被夹在技术的巨大利益、加速的竞赛，以及这种多方竞赛的现实之间。我能做的最好的事，就是投资安全技术，加速安全方面的进展，并且当我担心我们处理风险的能力跟不上技术发展的速度时，我就要更大声地疾呼。这就是我的回应。

![](https://i-blog.csdnimg.cn/img_convert/7a621d56d0db540d3f213370be9e58e4.png)

#### **那是我听过最无耻、最离谱的谎言**

主持人：我相信你也听过黄仁勋上个月对你的批评，他说：“Dario 认为只有他才能安全地构建这项技术，因此他想控制整个行业。” 你怎么看？

Dario Amodei：我从没说过那样的话。那是我听过最无耻、最离谱的谎言。

事实上，我说过很多次，Anthropic 的行动也证明了，我们的目标是一种 “竞相向上”（race to the top）。

我曾在播客上说过，Anthropic 的行动也表明，在一个 “竞相向下”（race to the bottom）的环境里，每个人都在比谁能更快地把东西推出来，谁赢了并不重要，因为所有人都输了。你造出了不安全的系统，它可能会帮助你的对手，或者导致经济问题，或者从对齐的角度看是不安全的。

而我所理解的 “竞相向上”，是谁赢了不重要，因为所有人都赢了。你为整个领域树立一个榜样。一个关键的例子就是我们的 “负责任的规模化政策”（Responsible Scaling Policy）。

我们是第一个发布这种政策的公司。我们没有说：“其他人都该这么做，不然你们就是坏人。” 我们没有试图把它当作一种优势。我们发布了它，然后鼓励其他所有人都这么做。

我们发现，在那之后的几个月里，其他公司内部那些试图推动类似政策的人，因为我们已经做了，就有了向领导层建言的理由和许可。这让整个行业都向前走了一步。在可解释性研究上也是如此，我们把研究成果公开发布给所有人，即便我们知道这其中有商业优势。在 “宪法 AI”、危险能力评估方面也是一样。

我们试图为这个领域树立一个榜样。但这和成为一个强大的商业竞争者之间存在一种相互作用。

我从没说过，也从未暗示过，我们公司应该是唯一一个构建这项技术的公司。我不知道任何人怎么能从我说的任何话里得出这种结论。这…… 这简直是…… 是的，这是一种令人难以置信的、恶意的曲解。

本文编译自 Alex Kantrowitz

原文 | youtube.com/watch?v=mYDSSRS-B5U

· · ·

📢 AI 产品爆发，但你的痛点解决了吗？

2025 全球产品经理大会

8 月 15–16 日 

北京 · 威斯汀酒店

互联网大厂、AI 创业公司、ToB/ToC 实战一线的产品人

12 大专题分享，洞察趋势、拆解路径、对话未来。

立即扫码领取大会 PPT

抢占 AI 产品下一波红利

![](https://i-blog.csdnimg.cn/img_convert/0714f520c50a880e76e6d55c11a70b64.png)